# -*- coding: utf-8 -*-
"""IMAGE DETECTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xZtIKrLGZtEPSK85qqAC7LPFippWXxZm

**Inspiration:**

**Purpose: to object detection in images by using YOLOv8.**

Object detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class (such as humans, buildings, or cars) in digital images and videos. When it comes to object detection, popular detection frameworks are

YOLO
SSD
Faster R-CNN

**What is YOLO exactly?**

YOLO (You Only Look Once) is a method / way to do object detection. It is the algorithm /strategy behind how the code is going to detect objects in the image.

Earlier detection frameworks, looked at different parts of the image multiple times at different scales and repurposed image classification technique to detect objects. This approach is slow and inefficient.

YOLO takes entirely different approach. It looks at the entire image only once and goes through the network once and detects objects. Hence the name. It is very fast. Thatâ€™s the reason it has got so popular.
"""

# 1. Install 7-Zip in the Colab environment
!apt-get install p7zip-full -y

# 2. Extract the .7z file to a folder
!7z e /content/.config/frame_9106_jpg.rf.edaac933241f83e08bf00984c0e0c85f.jpg.7z -o/content/.config -y

from google.colab import drive
drive.mount('/content/drive')

"""**Import Libraries**"""



import numpy as np
import pandas as pd
import cv2

from sklearn.utils import shuffle
from matplotlib.patches import Rectangle
import matplotlib.pyplot as plt

import warnings

warnings.simplefilter('ignore')

"""**Loading the Data**

"""

from google.colab import files
uploaded = files.upload()

import zipfile
import os

zip_path = "/content/Vehicles_Detection.v8i.yolov8.zip"
extract_path = "/content/Vehicles_Detection"

# Extract ZIP
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

import os

train_path = "/content/Vehicles_Detection/Vehicles_Detection.v8i.yolov8/train"
valid_path = "/content/Vehicles_Detection/Vehicles_Detection.v8i.yolov8/valid"

print("Train contents:", os.listdir(train_path))
print("Valid contents:", os.listdir(valid_path))

os.listdir(f"{train_path}/labels")[:3]  # should show .txt files

"""# **Classes**"""

with open("/content/Vehicles_Detection/Vehicles_Detection.v8i.yolov8/data.yaml") as f:
    print(f.read())

"""**Visualizing some images**"""

# Path to training images and labels
train_images_path = "/content/Vehicles_Detection/Vehicles_Detection.v8i.yolov8/train/images"
train_labels_path = "/content/Vehicles_Detection/Vehicles_Detection.v8i.yolov8/train/labels"

# List all image files in the training set
image_files = [f for f in os.listdir(train_images_path) if f.endswith(('.jpg', '.jpeg', '.png'))]

import os
import random
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Define the path to training images
train_images_path = "/content/Vehicles_Detection/Vehicles_Detection.v8i.yolov8/train/images"

# Get list of image files
image_files = [f for f in os.listdir(train_images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

# Choose a random image
img_file = random.choice(image_files)

# Full path to the selected image
img_path = os.path.join(train_images_path, img_file)

# Display the image
img = mpimg.imread(img_path)
plt.imshow(img)
plt.title(f"Random Image: {img_file}")
plt.axis('off')
plt.show()

# Load the corresponding label file (.txt) for the chosen image
label_file = img_file.replace('.jpg', '.txt').replace('.jpeg', '.txt').replace('.png', '.txt')
label_path = os.path.join(train_labels_path, label_file)

# Check if the label file exists
if os.path.exists(label_path):
    with open(label_path, 'r') as f:
        lines = f.readlines()
else:
    print(f"No label file found for {img_file}")

if os.path.exists(label_path):
    # Set up the plot for overlaying bounding boxes
    fig, ax = plt.subplots(figsize=(8, 8))
    ax.imshow(img)

    # Loop through each bounding box and draw it on the image
    for line in lines:
        # Each line contains: <class_id> <x_center> <y_center> <width> <height> (normalized)
        class_id, x_center, y_center, width, height = map(float, line.strip().split())

        # Convert normalized values to pixel values
        img_width, img_height = img.shape[1], img.shape[0]
        x_center *= img_width
        y_center *= img_height
        width *= img_width
        height *= img_height

        # Calculate the bounding box coordinates
        x1 = x_center - width / 2
        y1 = y_center - height / 2
        x2 = x_center + width / 2
        y2 = y_center + height / 2

        # Draw the bounding box
        ax.add_patch(plt.Rectangle((x1, y1), width, height, linewidth=2, edgecolor='r', facecolor='none'))

    plt.axis('off')
    plt.title(f"Image with Bounding Boxes: {img_file}")
    plt.show()

# Define class names as per your 'data.yaml' file
class_names = ['Bus', 'Car', 'Motorcycle', 'Pickup', 'Truck']

if os.path.exists(label_path):
    # Set up the plot for overlaying bounding boxes
    fig, ax = plt.subplots(figsize=(8, 8))
    ax.imshow(img)

    # Loop through each bounding box and draw it on the image
    for line in lines:
        # Each line contains: <class_id> <x_center> <y_center> <width> <height> (normalized)
        class_id, x_center, y_center, width, height = map(float, line.strip().split())

        # Convert normalized values to pixel values
        img_width, img_height = img.shape[1], img.shape[0]
        x_center *= img_width
        y_center *= img_height
        width *= img_width
        height *= img_height

        # Calculate the bounding box coordinates
        x1 = x_center - width / 2
        y1 = y_center - height / 2
        x2 = x_center + width / 2
        y2 = y_center + height / 2

        # Draw the bounding box
        ax.add_patch(plt.Rectangle((x1, y1), width, height, linewidth=2, edgecolor='r', facecolor='none'))

        # Add the class name as text on the image
        class_name = class_names[int(class_id)]  # Fetch class name from class_id
        ax.text(x1, y1, class_name, color='red', fontsize=12, verticalalignment='top', horizontalalignment='left',
                bbox=dict(facecolor='yellow', alpha=0.5))

    plt.axis('off')
    plt.title(f"Image with Bounding Boxes and Class Names: {img_file}")
    plt.show()

"""**Importing the Pretrained Model model**"""

!pip install ultralytics

from ultralytics import YOLO
import PIL
from PIL import Image
from IPython.display import display
import os
import pathlib

model = YOLO("yolov8m.pt")

"""**Analyzing YOLOv8 Detection Results: Object Classes, Coordinates, and Confidence Scores**"""

import os

base_path = "/content"
for root, dirs, files in os.walk(base_path):
    if 'frame' in str(files):  # We check for image-like names
        print(f"ðŸ“ {root}")
        for file in files:
            print(f"   - {file}")

import os

# List all files in the folder
extracted_files = os.listdir('/content/.config')
print("Extracted files:", extracted_files)

from ultralytics import YOLO
from IPython.display import Image, display

# Load your trained or pre-trained YOLOv8 model
model = YOLO('/content/yolov8m.pt')  # or your own model path

# Define the path to the extracted image
image_path = '/content/.config/frame_9106_jpg.rf.edaac933241f83e08bf00984c0e0c85f.jpg'

# Run prediction
results = model.predict(source=image_path, conf=0.3)

# Display the result image (YOLOv8 saves it automatically)
results[0].save(filename="/content/detected.jpg")
display(Image(filename="/content/detected.jpg"))

from ultralytics import YOLO
from IPython.display import Image, display

# Load a YOLOv8 model (pretrained or your custom one)
model = YOLO('/content/yolov8m.pt')  # Use your own model if available

# Set the image path
image_path = '/content/.config/frame_9106_jpg.rf.edaac933241f83e08bf00984c0e0c85f.jpg'

# Run prediction
results = model.predict(source=image_path, conf=0.3)

# Save and display the detected image
results[0].save(filename='/content/detected.jpg')
display(Image('/content/detected.jpg'))

# Access the model's class names directly
class_names = model.names

# Iterate over each detected object in the results
for box in results[0].boxes:
    # Get the class name (car, motorcycle, etc.)
    class_id = class_names[box.cls[0].item()]  # Get the class label using the class ID

    # Get the coordinates of the bounding box
    cords = box.xyxy[0].tolist()  # Format: [x1, y1, x2, y2]
    cords = [round(x) for x in cords]  # Round the coordinates to make them integers

    # Get the confidence score
    conf = round(box.conf[0].item(), 2)  # Round the confidence score to 2 decimal places

    # Print the results
    print("Object type:", class_id)
    print("Coordinates:", cords)
    print("Probability:", conf)
    print("---")

"""**MODEL BUILDING**

**Configure Training**
"""

!ls /content/

from google.colab import drive
drive.mount('/content/drive')

!ls /content/sample_data/

!unzip "/content/sample_data/Vehicles_Detection.v8i.yolov8 (3).zip" -d /content/your_dataset

yaml_content = """
train: /content/your_dataset/images/train
val: /content/your_dataset/images/val
test: /content/your_dataset/images/test

nc: 5
names: ['class_0', 'class_1', 'class_2', 'class_3', 'class_4']
"""

with open('dataset.yaml', 'w') as f:
    f.write(yaml_content)

!pip install ultralytics

!unzip "Vehicles_Detection.v8i.yolov8 (3).zip" -d /content/dataset

!ls /content/your_dataset/Vehicles_Detection.v8i.yolov8

# Commented out IPython magic to ensure Python compatibility.
# %%writefile dataset.yaml
# path: /content/your_dataset/Vehicles_Detection.v8i.yolov8
# train: train/images
# val: valid/images
# test: test/images
# 
# # Update these with your actual class information
# nc: 5  # Number of classes
# names: ['class_0', 'class_1', 'class_2', 'class_3', 'class_4']  # Class names

# Check training images exist
!ls /content/your_dataset/Vehicles_Detection.v8i.yolov8/train/images | head -5

# Check validation images exist
!ls /content/your_dataset/Vehicles_Detection.v8i.yolov8/valid/images | head -5

"""**Run Training**"""

from ultralytics import YOLO
import torch

# 1. Verify dataset structure
print("Verifying training images...")
!ls -lh "/content/your_dataset/Vehicles_Detection.v8i.yolov8/train/images" | head -5
print("\nVerifying validation images...")
!ls -lh "/content/your_dataset/Vehicles_Detection.v8i.yolov8/valid/images" | head -5

# 2. Load model (this will automatically download yolov8n.pt if not present)
model = YOLO("yolov8n.pt")  # You can also use "yolov8s.pt", "yolov8m.pt" etc.

# 3. Start training
results = model.train(
    data="dataset.yaml",
    epochs=30,
    batch=16,  # Reduce to 8 if you get CUDA out of memory errors
    imgsz=640,
    patience=10,  # Stop training if no improvement for 10 epochs
    device='cuda' if torch.cuda.is_available() else 'cpu',
    workers=8,
    optimizer='auto',
    lr0=0.01,  # Initial learning rate
    lrf=0.01,  # Final learning rate
    momentum=0.937,
    weight_decay=0.0005,
    warmup_epochs=3.0,
    warmup_momentum=0.8,
    warmup_bias_lr=0.1,
    box=7.5,  # box loss gain
    cls=0.5,  # cls loss gain
    dfl=1.5,  # dfl loss gain
    close_mosaic=10,  # Disable mosaic augmentation last 10 epochs
)

"""**Monitor Training Progress**"""

# Search for training results in common locations
!find /content -name "results.csv"  # For Google Colab
# OR for local environments
# !find ~ -name "results.csv" 2>/dev/null

"""**Model Evaluation**"""

import pandas as pd
import matplotlib.pyplot as plt

# 1. Load and clean your results
results_path = "/content/runs/detect/train6/results.csv"
results = pd.read_csv(results_path)

# Clean column names (remove extra spaces)
results.columns = results.columns.str.strip()

# 2. Create comprehensive plots
plt.figure(figsize=(15, 12))

# Loss metrics
plt.subplot(3, 2, 1)
plt.plot(results['epoch'], results['train/box_loss'], label='Train')
plt.plot(results['epoch'], results['val/box_loss'], label='Validation', linestyle='--')
plt.title('Box Loss')
plt.ylabel('Loss')
plt.legend()

plt.subplot(3, 2, 2)
plt.plot(results['epoch'], results['train/cls_loss'], label='Train')
plt.plot(results['epoch'], results['val/cls_loss'], label='Validation', linestyle='--')
plt.title('Classification Loss')
plt.legend()

# Accuracy metrics
plt.subplot(3, 2, 3)
plt.plot(results['epoch'], results['metrics/mAP50(B)'])
plt.title('mAP@0.5')
plt.ylabel('Precision')

plt.subplot(3, 2, 4)
plt.plot(results['epoch'], results['metrics/mAP50-95(B)'])
plt.title('mAP@0.5:0.95')
plt.ylabel('Precision')

# Learning rate
plt.subplot(3, 2, 5)
plt.plot(results['epoch'], results['lr/pg0'])
plt.title('Learning Rate')
plt.xlabel('Epoch')
plt.ylabel('LR')

plt.tight_layout()
plt.show()

# Find best/worst epochs
best_epoch = results['metrics/mAP50(B)'].idxmax()
print(f"Best Epoch: {best_epoch}")
print(results.iloc[best_epoch][['epoch', 'metrics/mAP50(B)', 'val/box_loss']])

# Plot precision-recall curve
from ultralytics import YOLO
model = YOLO("runs/detect/train6/weights/best.pt")
model.val(plots=True)  # Generates precision-recall curves

"""**Run Inference**"""

import os

# Check where your script is running from
print("Current working directory:", os.getcwd())

# Check if files exist at expected location
test_path = '/content/your_dataset/Vehicles_Detection.v8i.yolov8/valid/images/frame_0002_jpg.rf.a929cd43bfa0953ace4ea9ea00fa9ba7.jpg'
print("File exists?", os.path.exists(test_path))

from google.colab import files
import os

# Create directory if needed
os.makedirs('/content/test_images', exist_ok=True)

# Upload interactively (will show file picker)
uploaded = files.upload()

# Move to our test_images folder
for filename in uploaded.keys():
    os.rename(filename, f'/content/test_images/{filename}')

import os
import zipfile
from glob import glob
from PIL import Image
from IPython.display import display

# 1. Unzip the dataset (only need to do this once)
zip_path = '/content/sample_data/Vehicles_Detection.v8i.yolov8 (3).zip'
extract_path = '/content/vehicles_data'

if not os.path.exists(extract_path):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)
    print("Extraction complete!")
else:
    print("Files already extracted")

# 2. Locate the validation images
image_paths = sorted(glob(f'{extract_path}/valid/images/*.jpg'))
print(f"Found {len(image_paths)} validation images")

# Quick verification
if image_paths:
    display(Image.open(image_paths[0]))  # Show first image
else:
    print("Error: No images found. Check the extract path!")

# Check training images exist
!ls /content/your_dataset/Vehicles_Detection.v8i.yolov8/train/images | head -5

# Check validation images exist
!ls /content/your_dataset/Vehicles_Detection.v8i.yolov8/valid/images | head -5



import os
from glob import glob

# 1. Define your dataset root (adjust based on actual location)
dataset_root = '/content/your_dataset/Vehicles_Detection.v8i.yolov8'

# 2. Get your specific validation images (from your list)
val_images = [
    'frame_0002_jpg.rf.a929cd43bfa0953ace4ea9ea00fa9ba7.jpg',
    'frame_0087_jpg.rf.6911e25ecb00139750616b606571e714.jpg',
    'frame_0182_jpg.rf.24ccc1dc2e78b06ec38094471560e981.jpg',
    'frame_0435_jpg.rf.b64a627a937f4b21417074ddc983c184.jpg'
]

# 3. Build full paths
image_paths = [f"{dataset_root}/valid/images/{img}" for img in val_images]

# 4. Verify paths exist
missing = [p for p in image_paths if not os.path.exists(p)]
if missing:
    print(f"Missing files: {missing}")
else:
    print("All files found - proceeding with inference")

    # 5. Run inference
    results = model.predict(image_paths,
                          conf=0.3,
                          save=True,
                          save_txt=True)

    # 6. Display results
    for r in results:
        print(f"\nResults for {os.path.basename(r.path)}:")
        display(r.show())  # Colab-friendly display
        print("Detected objects:")
        for box in r.boxes:
            print(f"- {model.names[int(box.cls)]} (confidence: {box.conf:.2f})")

import os
import zipfile

# Path to your zip file
zip_path = '/content/sample_data/Vehicles_Detection.v8i.yolov8 (3).zip'
extract_to = '/content/vehicles_data'

# Create directory if needed
os.makedirs(extract_to, exist_ok=True)

# Unzip the file (only need to do this once)
if not os.path.exists(os.path.join(extract_to, 'valid')):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to)
    print("Dataset extracted successfully!")
else:
    print("Dataset already extracted")

# Verify the structure
!ls {extract_to}

import os
from IPython.display import display, Markdown

# 1. First, let's confirm the exact extracted structure
dataset_root = '/content/vehicles_data'
valid_images_path = os.path.join(dataset_root, 'valid', 'images')

# 2. Check if the directory exists
if not os.path.exists(valid_images_path):
    display(Markdown("**Error**: The validation images directory doesn't exist!"))
    display(Markdown(f"Current structure in {dataset_root}:"))
    !ls -R {dataset_root} | head -20
else:
    # 3. Get ACTUAL filenames (they might have different suffixes)
    actual_files = os.listdir(valid_images_path)
    display(Markdown(f"**Found {len(actual_files)} images in validation set**"))
    display(Markdown("First 5 files:"))
    display(actual_files[:5])

    # 4. Try to match your requested files
    display(Markdown("\n**Matching your requested files:**"))
    found_count = 0
    for requested in val_images:
        # Find matching file (might have different .rf. suffix)
        matches = [f for f in actual_files if requested.split('.rf.')[0] in f]
        if matches:
            print(f"âœ“ Found match for {requested}: {matches[0]}")
            found_count += 1
        else:
            print(f"âœ— No match for {requested}")

    # 5. Solution: Use the ACTUAL filenames we found
    if found_count > 0:
        display(Markdown("\n**Solution:** Use these corrected paths:"))
        corrected_paths = [os.path.join(valid_images_path, f) for f in actual_files if any(req.split('.rf.')[0] in f for req in val_images)]
        for path in corrected_paths:
            print(path)

        # Now you can use corrected_paths with model.predict()
    else:
        display(Markdown("\n**No matches found**. Possible issues:"))
        display(Markdown("- The ZIP file might contain different images"))
        display(Markdown("- The filenames might have changed"))

import os
from IPython.display import display, Markdown

# 1. Update the base path to include the nested folder
dataset_root = '/content/vehicles_data/Vehicles_Detection.v8i.yolov8'
valid_images_path = os.path.join(dataset_root, 'valid', 'images')

# 2. Verify the corrected path exists
if not os.path.exists(valid_images_path):
    display(Markdown("**Error**: Still can't find validation images!"))
    !ls -R {dataset_root} | head -20
else:
    display(Markdown(f"**Success! Found validation images at:** `{valid_images_path}`"))

    # 3. List available images
    actual_files = sorted(os.listdir(valid_images_path))
    display(Markdown(f"Found {len(actual_files)} validation images. First 5:"))
    display(actual_files[:5])

    # 4. Find your specific frames (using partial matching)
    target_frames = [
        'frame_0002_jpg',
        'frame_0087_jpg',
        'frame_0182_jpg',
        'frame_0435_jpg'
    ]

    matched_paths = []
    for frame in target_frames:
        matches = [f for f in actual_files if frame in f]
        if matches:
            matched_paths.append(os.path.join(valid_images_path, matches[0]))

    # 5. Results
    if matched_paths:
        display(Markdown("\n**Matched files:**"))
        for path in matched_paths:
            print(path)

        # Now you can use these paths with model.predict()
    else:
        display(Markdown("\n**No matches found**. Try:"))
        display(Markdown("- Checking different frame numbers"))
        display(Markdown("- Using the test set images instead"))
        display(Markdown("Available test images:"))
        !ls {dataset_root}/test/images | head -5

# Get first 4 validation images
val_images = sorted([f for f in os.listdir(valid_images_path) if f.endswith('.jpg')])[:4]
image_paths = [os.path.join(valid_images_path, img) for img in val_images]

# Run prediction
results = model.predict(image_paths, conf=0.3)

# Display results (with fixed tensor handling)
for i, r in enumerate(results):
    print(f"\nImage {i+1}: {os.path.basename(r.path)}")
    display(r.show())

    if len(r.boxes) > 0:
        print("Detected objects:")
        for box in r.boxes:
            class_id = int(box.cls.item())
            conf = box.conf.item()
            print(f"  {model.names[class_id]} ({conf:.2f})")
    else:
        print("No detections")

"""**Saving the Model**"""

from ultralytics import YOLO

# Save in PyTorch format (.pt)
model.save("yolov8_custom.pt")  # Saves to current working directory

# Optional: Export to ONNX for better compatibility
model.export(format="onnx")  # Creates 'yolov8_custom.onnx'

from google.colab import files

# Download both formats
files.download("yolov8_custom.pt")
files.download("yolov8_custom.onnx")  # Optional

from ultralytics import YOLO
from google.colab import files
import os

# 1. Verify model exists
model_path = "yolov8_custom.pt"
if not os.path.exists(model_path):
    raise FileNotFoundError("Model not found - train or load your model first")

# 2. Save PyTorch format (always works)
model.save(model_path)

# 3. Attempt ONNX export (with error handling)
try:
    onnx_path = model.export(format="onnx")  # Returns path of exported model
    print(f"ONNX model saved to: {onnx_path}")
except Exception as e:
    print(f"ONNX export failed: {e}")
    onnx_path = None

# 4. Download what's available
print("\nDownloading files...")
files.download(model_path)  # This will always work

if onnx_path and os.path.exists(onnx_path):
    files.download(onnx_path)
else:
    print("Skipping ONNX download - file not available")

import torch
torch.save(model.model.state_dict(), "yolov8_custom_weights.pt")
files.download("yolov8_custom_weights.pt")

# 1. Generate requirements.txt with exact versions
!pip freeze > requirements.txt

# 2. Verify the file was created
!head -n 10 requirements.txt  # Show first 10 lines

# 3. Download the file
from google.colab import files
files.download('requirements.txt')